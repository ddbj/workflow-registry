{"content":"version 1.0\n\n## Copyright Broad Institute, 2017\n##\n## This WDL workflow runs GATK4 Mutect 2 on a single tumor-normal pair or on a single tumor sample,\n## and performs additional filtering and functional annotation tasks.\n##\n## Main requirements/expectations :\n## - One analysis-ready BAM file (and its index) for each sample\n##\n## Description of inputs:\n##\n## ** Runtime **\n## gatk_docker: docker image to use for GATK 4 Mutect2\n## preemptible: how many preemptions to tolerate before switching to a non-preemptible machine (on Google)\n## max_retries: how many times to retry failed tasks -- very important on the cloud when there are transient errors\n## gatk_override: (optional) local file or Google bucket path to a GATK 4 java jar file to be used instead of the GATK 4 jar\n##                in the docker image.  This must be supplied when running in an environment that does not support docker\n##                (e.g. SGE cluster on a Broad on-prem VM)\n##\n## ** Workflow options **\n## intervals: genomic intervals (will be used for scatter)\n## scatter_count: number of parallel jobs to generate when scattering over intervals\n## m2_extra_args, m2_extra_filtering_args: additional arguments for Mutect2 calling and filtering (optional)\n## split_intervals_extra_args: additional arguments for splitting intervals before scattering (optional)\n## run_orientation_bias_mixture_model_filter: (optional) if true, filter orientation bias sites with the read orientation artifact mixture model.\n##\n## ** Primary inputs **\n## ref_fasta, ref_fai, ref_dict: reference genome, index, and dictionary\n## tumor_bam, tumor_bam_index: BAM and index for the tumor sample\n## normal_bam, normal_bam_index: BAM and index for the normal sample\n##\n## ** Primary resources ** (optional but strongly recommended)\n## pon, pon_idx: optional panel of normals (and its index) in VCF format containing probable technical artifacts (false positves)\n## gnomad, gnomad_idx: optional database of known germline variants (and its index) (see http://gnomad.broadinstitute.org/downloads)\n## variants_for_contamination, variants_for_contamination_idx: VCF of common variants (and its index)with allele frequencies for calculating contamination\n##\n## ** Secondary resources ** (for optional tasks)\n## realignment_index_bundle: resource for FilterAlignmentArtifacts, which runs if and only if it is specified.  Generated by BwaMemIndexImageCreator.\n##\n## Funcotator parameters (see Funcotator help for more details).\n## funco_reference_version: \"hg19\" for hg19 or b37.  \"hg38\" for hg38.  Default: \"hg19\"\n## funco_output_format: \"MAF\" to produce a MAF file, \"VCF\" to procude a VCF file.  Default: \"MAF\"\n## funco_compress: (Only valid if funco_output_format == \"VCF\" )  If true, will compress the output of Funcotator.  If false, produces an uncompressed output file.  Default: false\n## funco_use_gnomad_AF: If true, will include gnomAD allele frequency annotations in output by connecting to the internet to query gnomAD (this impacts performance).  If false, will not annotate with gnomAD.  Default: false\n## funco_transcript_selection_mode: How to select transcripts in Funcotator.  ALL, CANONICAL, or BEST_EFFECT\n## funco_transcript_selection_list: Transcripts (one GENCODE ID per line) to give priority during selection process.\n## funco_data_sources_tar_gz:  Funcotator datasources tar gz file.  Bucket location is recommended when running on the cloud.\n## funco_annotation_defaults:  Default values for annotations, when values are unspecified.  Specified as  <ANNOTATION>:<VALUE>.  For example:  \"Center:Broad\"\n## funco_annotation_overrides:  Values for annotations, even when values are unspecified.  Specified as  <ANNOTATION>:<VALUE>.  For example:  \"Center:Broad\"\n## funcotator_excluded_fields:  Annotations that should not appear in the output (VCF or MAF).  Specified as  <ANNOTATION>.  For example:  \"ClinVar_ALLELEID\"\n## funco_filter_funcotations: If true, will only annotate variants that have passed filtering (. or PASS value in the FILTER column).  If false, will annotate all variants in the input file.  Default: true\n## funcotator_extra_args: Any additional arguments to pass to Funcotator.  Default: \"\"\n##\n## Outputs :\n## - One VCF file and its index with primary filtering applied; secondary filtering and functional annotation if requested; a bamout.bam\n##   file of reassembled reads if requested\n##\n## Cromwell version support\n## - Successfully tested on v34\n##\n## LICENSING :\n## This script is released under the WDL source code license (BSD-3) (see LICENSE in\n## https://github.com/broadinstitute/wdl). Note however that the programs it calls may\n## be subject to different licenses. Users are responsible for checking that they are\n## authorized to run all programs before running this script. Please see the docker\n## pages at https://hub.docker.com/r/broadinstitute/* for detailed licensing information\n## pertaining to the included programs.\n\nstruct Runtime {\n    String gatk_docker\n    File? gatk_override\n    Int max_retries\n    Int preemptible\n    Int cpu\n    Int machine_mem\n    Int command_mem\n    Int disk\n    Int boot_disk_size\n}\n\nworkflow Mutect2 {\n    input {\n      # Mutect2 inputs\n      File? intervals\n      File ref_fasta\n      File ref_fai\n      File ref_dict\n      File tumor_reads\n      File tumor_reads_index\n      File? normal_reads\n      File? normal_reads_index\n      File? pon\n      File? pon_idx\n      Int scatter_count\n      File? gnomad\n      File? gnomad_idx\n      File? variants_for_contamination\n      File? variants_for_contamination_idx\n      File? realignment_index_bundle\n      String? realignment_extra_args\n      Boolean? run_orientation_bias_mixture_model_filter\n      String? m2_extra_args\n      String? m2_extra_filtering_args\n      String? split_intervals_extra_args\n      Boolean? make_bamout\n      Boolean? compress_vcfs\n      File? gga_vcf\n      File? gga_vcf_idx\n\n      # Funcotator inputs\n      Boolean? run_funcotator\n      String? sequencing_center\n      String? sequence_source\n      String? funco_reference_version\n      String? funco_output_format\n      Boolean? funco_compress\n      Boolean? funco_use_gnomad_AF\n      File? funco_data_sources_tar_gz\n      String? funco_transcript_selection_mode\n      File? funco_transcript_selection_list\n      Array[String]? funco_annotation_defaults\n      Array[String]? funco_annotation_overrides\n      Array[String]? funcotator_excluded_fields\n      Boolean? funco_filter_funcotations\n      String? funcotator_extra_args\n\n      String funco_default_output_format = \"MAF\"\n\n      # runtime\n      String gatk_docker\n      File? gatk_override\n      String basic_bash_docker = \"ubuntu:16.04\"\n      Boolean? filter_funcotations\n\n      Int? preemptible\n      Int? max_retries\n      Int small_task_cpu = 2\n      Int small_task_mem = 4\n      Int small_task_disk = 100\n      Int boot_disk_size = 12\n      Int learn_read_orientation_mem = 8000\n      Int filter_alignment_artifacts_mem = 9000\n\n      # Use as a last resort to increase the disk given to every task in case of ill behaving data\n      Int? emergency_extra_disk\n\n      # These are multipliers to multipler inputs by to make sure we have enough disk to accommodate for possible output sizes\n      # Large is for Bams/WGS vcfs\n      # Small is for metrics/other vcfs\n      Float large_input_to_output_multiplier = 2.25\n      Float small_input_to_output_multiplier = 2.0\n      Float cram_to_bam_multiplier = 6.0\n    }\n\n    Int preemptible_or_default = select_first([preemptible, 2])\n    Int max_retries_or_default = select_first([max_retries, 2])\n\n    Boolean compress = select_first([compress_vcfs, false])\n    Boolean run_ob_filter = select_first([run_orientation_bias_mixture_model_filter, false])\n    Boolean make_bamout_or_default = select_first([make_bamout, false])\n    Boolean run_funcotator_or_default = select_first([run_funcotator, false])\n    Boolean filter_funcotations_or_default = select_first([filter_funcotations, true])\n\n    # Disk sizes used for dynamic sizing\n    Int ref_size = ceil(size(ref_fasta, \"GB\") + size(ref_dict, \"GB\") + size(ref_fai, \"GB\"))\n    Int tumor_reads_size = ceil(size(tumor_reads, \"GB\") + size(tumor_reads_index, \"GB\"))\n    Int gnomad_vcf_size = if defined(gnomad) then ceil(size(gnomad, \"GB\")) else 0\n    Int normal_reads_size = if defined(normal_reads) then ceil(size(normal_reads, \"GB\") + size(normal_reads_index, \"GB\")) else 0\n\n    # If no tar is provided, the task downloads one from broads ftp server\n    Int funco_tar_size = if defined(funco_data_sources_tar_gz) then ceil(size(funco_data_sources_tar_gz, \"GB\") * 3) else 100\n    Int gatk_override_size = if defined(gatk_override) then ceil(size(gatk_override, \"GB\")) else 0\n\n    # This is added to every task as padding, should increase if systematically you need more disk for every call\n    Int disk_pad = 10 + gatk_override_size + select_first([emergency_extra_disk,0])\n\n    # logic about output file names -- these are the names *without* .vcf extensions\n    String output_basename = basename(basename(tumor_reads, \".bam\"),\".cram\")  #hacky way to strip either .bam or .cram\n    String unfiltered_name = output_basename + \"-unfiltered\"\n    String filtered_name = output_basename + \"-filtered\"\n    String funcotated_name = output_basename + \"-funcotated\"\n\n    String output_vcf_name = output_basename + \".vcf\"\n\n    Int tumor_cram_to_bam_disk = ceil(tumor_reads_size * cram_to_bam_multiplier)\n    Int normal_cram_to_bam_disk = ceil(normal_reads_size * cram_to_bam_multiplier)\n\n    Runtime standard_runtime = {\"gatk_docker\": gatk_docker, \"gatk_override\": gatk_override,\n            \"max_retries\": max_retries_or_default, \"preemptible\": preemptible_or_default, \"cpu\": small_task_cpu,\n            \"machine_mem\": small_task_mem * 1000, \"command_mem\": small_task_mem * 1000 - 500,\n            \"disk\": small_task_disk + disk_pad, \"boot_disk_size\": boot_disk_size}\n\n    if (basename(tumor_reads) != basename(tumor_reads, \".cram\")) {\n        call CramToBam as TumorCramToBam {\n            input:\n                ref_fasta = ref_fasta,\n                ref_fai = ref_fai,\n                ref_dict = ref_dict,\n                cram = tumor_reads,\n                crai = tumor_reads_index,\n                name = output_basename,\n                disk_size = tumor_cram_to_bam_disk\n        }\n    }\n\n    String normal_or_empty = select_first([normal_reads, \"\"])\n    if (basename(normal_or_empty) != basename(normal_or_empty, \".cram\")) {\n        String normal_basename = basename(basename(normal_or_empty, \".bam\"),\".cram\")\n        call CramToBam as NormalCramToBam {\n            input:\n                ref_fasta = ref_fasta,\n                ref_fai = ref_fai,\n                ref_dict = ref_dict,\n                cram = normal_reads,\n                crai = normal_reads_index,\n                name = normal_basename,\n                disk_size = normal_cram_to_bam_disk\n        }\n    }\n\n    File tumor_bam = select_first([TumorCramToBam.output_bam, tumor_reads])\n    File tumor_bai = select_first([TumorCramToBam.output_bai, tumor_reads_index])\n    File? normal_bam = if defined(normal_reads) then select_first([NormalCramToBam.output_bam, normal_reads]) else normal_reads\n    File? normal_bai = if defined(normal_reads) then select_first([NormalCramToBam.output_bai, normal_reads_index]) else normal_reads_index\n\n    Int tumor_bam_size = ceil(size(tumor_bam, \"GB\") + size(tumor_bai, \"GB\"))\n    Int normal_bam_size = if defined(normal_bam) then ceil(size(normal_bam, \"GB\") + size(normal_bai, \"GB\")) else 0\n\n    Int m2_output_size = tumor_bam_size / scatter_count\n    #TODO: do we need to change this disk size now that NIO is always going to happen (for the google backend only)\n    Int m2_per_scatter_size = (tumor_bam_size + normal_bam_size) + ref_size + gnomad_vcf_size + m2_output_size + disk_pad\n\n    call SplitIntervals {\n        input:\n            intervals = intervals,\n            ref_fasta = ref_fasta,\n            ref_fai = ref_fai,\n            ref_dict = ref_dict,\n            scatter_count = scatter_count,\n            split_intervals_extra_args = split_intervals_extra_args,\n            runtime_params = standard_runtime\n    }\n\n    scatter (subintervals in SplitIntervals.interval_files ) {\n        call M2 {\n            input:\n                intervals = subintervals,\n                ref_fasta = ref_fasta,\n                ref_fai = ref_fai,\n                ref_dict = ref_dict,\n                tumor_bam = tumor_bam,\n                tumor_bai = tumor_bai,\n                normal_bam = normal_bam,\n                normal_bai = normal_bai,\n                pon = pon,\n                pon_idx = pon_idx,\n                gnomad = gnomad,\n                gnomad_idx = gnomad_idx,\n                preemptible = preemptible,\n                max_retries = max_retries,\n                m2_extra_args = m2_extra_args,\n                variants_for_contamination = variants_for_contamination,\n                variants_for_contamination_idx = variants_for_contamination_idx,\n                make_bamout = make_bamout_or_default,\n                run_ob_filter = run_ob_filter,\n                compress = compress,\n                gga_vcf = gga_vcf,\n                gga_vcf_idx = gga_vcf_idx,\n                gatk_override = gatk_override,\n                gatk_docker = gatk_docker,\n                disk_space = m2_per_scatter_size\n        }\n    }\n\n    Int merged_vcf_size = ceil(size(M2.unfiltered_vcf, \"GB\"))\n    Int merged_bamout_size = ceil(size(M2.output_bamOut, \"GB\"))\n\n    if (run_ob_filter) {\n        call LearnReadOrientationModel {\n            input:\n                f1r2_tar_gz = M2.f1r2_counts,\n                runtime_params = standard_runtime,\n                mem = learn_read_orientation_mem\n        }\n    }\n\n    call MergeVCFs {\n        input:\n            input_vcfs = M2.unfiltered_vcf,\n            input_vcf_indices = M2.unfiltered_vcf_idx,\n            output_name = unfiltered_name,\n            compress = compress,\n            runtime_params = standard_runtime\n    }\n\n    if (make_bamout_or_default) {\n        call MergeBamOuts {\n            input:\n                ref_fasta = ref_fasta,\n                ref_fai = ref_fai,\n                ref_dict = ref_dict,\n                bam_outs = M2.output_bamOut,\n                output_vcf_name = basename(MergeVCFs.merged_vcf, \".vcf\"),\n                runtime_params = standard_runtime,\n                disk_space = ceil(merged_bamout_size * large_input_to_output_multiplier) + disk_pad,\n        }\n    }\n\n    call MergeStats { input: stats = M2.stats, runtime_params = standard_runtime }\n\n    if (defined(variants_for_contamination)) {\n        call MergePileupSummaries as MergeTumorPileups {\n            input:\n                input_tables = flatten(M2.tumor_pileups),\n                output_name = output_basename,\n                ref_dict = ref_dict,\n                runtime_params = standard_runtime\n        }\n\n        if (defined(normal_bam)){\n            call MergePileupSummaries as MergeNormalPileups {\n                input:\n                    input_tables = flatten(M2.normal_pileups),\n                    output_name = output_basename,\n                    ref_dict = ref_dict,\n                    runtime_params = standard_runtime\n            }\n        }\n\n        call CalculateContamination {\n            input:\n                tumor_pileups = MergeTumorPileups.merged_table,\n                normal_pileups = MergeNormalPileups.merged_table,\n                runtime_params = standard_runtime\n        }\n    }\n\n    call Filter {\n        input:\n            ref_fasta = ref_fasta,\n            ref_fai = ref_fai,\n            ref_dict = ref_dict,\n            intervals = intervals,\n            unfiltered_vcf = MergeVCFs.merged_vcf,\n            unfiltered_vcf_idx = MergeVCFs.merged_vcf_idx,\n            output_name = filtered_name,\n            compress = compress,\n            mutect_stats = MergeStats.merged_stats,\n            contamination_table = CalculateContamination.contamination_table,\n            maf_segments = CalculateContamination.maf_segments,\n            artifact_priors_tar_gz = LearnReadOrientationModel.artifact_prior_table,\n            m2_extra_filtering_args = m2_extra_filtering_args,\n            runtime_params = standard_runtime,\n            disk_space = ceil(size(MergeVCFs.merged_vcf, \"GB\") * small_input_to_output_multiplier) + disk_pad\n    }\n\n    if (defined(realignment_index_bundle)) {\n        call FilterAlignmentArtifacts {\n            input:\n                ref_fasta = ref_fasta,\n                ref_fai = ref_fai,\n                ref_dict = ref_dict,\n                bam = tumor_bam,\n                bai = tumor_bai,\n                realignment_index_bundle = select_first([realignment_index_bundle]),\n                realignment_extra_args = realignment_extra_args,\n                compress = compress,\n                output_name = filtered_name,\n                input_vcf = Filter.filtered_vcf,\n                input_vcf_idx = Filter.filtered_vcf_idx,\n                runtime_params = standard_runtime,\n                mem = filter_alignment_artifacts_mem\n        }\n    }\n\n    if (run_funcotator_or_default) {\n        File funcotate_vcf_input = select_first([FilterAlignmentArtifacts.filtered_vcf, Filter.filtered_vcf])\n        File funcotate_vcf_input_index = select_first([FilterAlignmentArtifacts.filtered_vcf_idx, Filter.filtered_vcf_idx])\n        call Funcotate {\n            input:\n                ref_fasta = ref_fasta,\n                ref_fai = ref_fai,\n                ref_dict = ref_dict,\n                input_vcf = funcotate_vcf_input,\n                input_vcf_idx = funcotate_vcf_input_index,\n                reference_version = select_first([funco_reference_version, \"hg19\"]),\n                output_file_base_name = basename(funcotate_vcf_input, \".vcf\") + \".annotated\",\n                output_format = if defined(funco_output_format) then \"\" + funco_output_format else funco_default_output_format,\n                compress = if defined(funco_compress) then select_first([funco_compress]) else false,\n                use_gnomad = if defined(funco_use_gnomad_AF) then select_first([funco_use_gnomad_AF]) else false,\n                data_sources_tar_gz = funco_data_sources_tar_gz,\n                case_id = M2.tumor_sample[0],\n                control_id = M2.normal_sample[0],\n                sequencing_center = sequencing_center,\n                sequence_source = sequence_source,\n                transcript_selection_mode = funco_transcript_selection_mode,\n                transcript_selection_list = funco_transcript_selection_list,\n                annotation_defaults = funco_annotation_defaults,\n                annotation_overrides = funco_annotation_overrides,\n                funcotator_excluded_fields = funcotator_excluded_fields,\n                filter_funcotations = filter_funcotations_or_default,\n                extra_args = funcotator_extra_args,\n                runtime_params = standard_runtime,\n                disk_space = ceil(size(funcotate_vcf_input, \"GB\") * large_input_to_output_multiplier)  + funco_tar_size + disk_pad\n        }\n    }\n\n    output {\n        File filtered_vcf = select_first([FilterAlignmentArtifacts.filtered_vcf, Filter.filtered_vcf])\n        File filtered_vcf_idx = select_first([FilterAlignmentArtifacts.filtered_vcf_idx, Filter.filtered_vcf_idx])\n        File filtering_stats = Filter.filtering_stats\n        File mutect_stats = MergeStats.merged_stats\n        File? contamination_table = CalculateContamination.contamination_table\n\n        File? funcotated_file = Funcotate.funcotated_output_file\n        File? funcotated_file_index = Funcotate.funcotated_output_file_index\n        File? bamout = MergeBamOuts.merged_bam_out\n        File? bamout_index = MergeBamOuts.merged_bam_out_index\n        File? maf_segments = CalculateContamination.maf_segments\n        File? read_orientation_model_params = LearnReadOrientationModel.artifact_prior_table\n    }\n}\n\ntask CramToBam {\n    input {\n      File ref_fasta\n      File ref_fai\n      File ref_dict\n      #cram and crai must be optional since Normal cram is optional\n      File? cram\n      File? crai\n      String name\n      Int disk_size\n      Int? mem\n    }\n\n    Int machine_mem = if defined(mem) then mem * 1000 else 6000\n\n    #Calls samtools view to do the conversion\n    command {\n        #Set -e and -o says if any command I run fails in this script, make sure to return a failure\n        set -e\n        set -o pipefail\n\n        samtools view -h -T ~{ref_fasta} ~{cram} |\n            samtools view -b -o ~{name}.bam -\n        samtools index -b ~{name}.bam\n        mv ~{name}.bam.bai ~{name}.bai\n    }\n\n    runtime {\n        docker: \"us.gcr.io/broad-gotc-prod/genomes-in-the-cloud:2.3.3-1513176735\"\n        memory: machine_mem + \" MB\"\n        disks: \"local-disk \" + disk_size + \" HDD\"\n    }\n\n    output {\n        File output_bam = \"~{name}.bam\"\n        File output_bai = \"~{name}.bai\"\n    }\n}\n\ntask SplitIntervals {\n    input {\n      File? intervals\n      File ref_fasta\n      File ref_fai\n      File ref_dict\n      Int scatter_count\n      String? split_intervals_extra_args\n\n      # runtime\n      Runtime runtime_params\n    }\n\n    command {\n        set -e\n        export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" runtime_params.gatk_override}\n\n        mkdir interval-files\n        gatk --java-options \"-Xmx~{runtime_params.command_mem}m\" SplitIntervals \\\n            -R ~{ref_fasta} \\\n            ~{\"-L \" + intervals} \\\n            -scatter ~{scatter_count} \\\n            -O interval-files \\\n            ~{split_intervals_extra_args}\n        cp interval-files/*.interval_list .\n    }\n\n    runtime {\n        docker: runtime_params.gatk_docker\n        bootDiskSizeGb: runtime_params.boot_disk_size\n        memory: runtime_params.machine_mem + \" MB\"\n        disks: \"local-disk \" + runtime_params.disk + \" HDD\"\n        preemptible: runtime_params.preemptible\n        maxRetries: runtime_params.max_retries\n        cpu: runtime_params.cpu\n    }\n\n    output {\n        Array[File] interval_files = glob(\"*.interval_list\")\n    }\n}\n\ntask M2 {\n    input {\n      File? intervals\n      File ref_fasta\n      File ref_fai\n      File ref_dict\n      File tumor_bam\n      File tumor_bai\n      File? normal_bam\n      File? normal_bai\n      File? pon\n      File? pon_idx\n      File? gnomad\n      File? gnomad_idx\n      String? m2_extra_args\n      Boolean? make_bamout\n      Boolean? run_ob_filter\n      Boolean compress\n      File? gga_vcf\n      File? gga_vcf_idx\n      File? variants_for_contamination\n      File? variants_for_contamination_idx\n\n      File? gatk_override\n\n      # runtime\n      String gatk_docker\n      Int? mem\n      Int? preemptible\n      Int? max_retries\n      Int? disk_space\n      Int? cpu\n      Boolean use_ssd = false\n    }\n\n    String output_vcf = \"output\" + if compress then \".vcf.gz\" else \".vcf\"\n    String output_vcf_idx = output_vcf + if compress then \".tbi\" else \".idx\"\n\n    String output_stats = output_vcf + \".stats\"\n\n    # Mem is in units of GB but our command and memory runtime values are in MB\n    Int machine_mem = if defined(mem) then mem * 1000 else 3500\n    Int command_mem = machine_mem - 500\n\n    parameter_meta{\n      intervals: {localization_optional: true}\n      ref_fasta: {localization_optional: true}\n      ref_fai: {localization_optional: true}\n      ref_dict: {localization_optional: true}\n      tumor_bam: {localization_optional: true}\n      tumor_bai: {localization_optional: true}\n      normal_bam: {localization_optional: true}\n      normal_bai: {localization_optional: true}\n      pon: {localization_optional: true}\n      pon_idx: {localization_optional: true}\n      gnomad: {localization_optional: true}\n      gnomad_idx: {localization_optional: true}\n      gga_vcf: {localization_optional: true}\n      gga_vcf_idx: {localization_optional: true}\n      variants_for_contamination: {localization_optional: true}\n      variants_for_contamination_idx: {localization_optional: true}\n    }\n\n    command <<<\n        set -e\n\n        export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" gatk_override}\n\n        # We need to create these files regardless, even if they stay empty\n        touch bamout.bam\n        touch f1r2.tar.gz\n        echo \"\" > normal_name.txt\n\n        gatk --java-options \"-Xmx~{command_mem}m\" GetSampleName -R ~{ref_fasta} -I ~{tumor_bam} -O tumor_name.txt -encode\n        tumor_command_line=\"-I ~{tumor_bam} -tumor `cat tumor_name.txt`\"\n\n        if [[ ! -z \"~{normal_bam}\" ]]; then\n            gatk --java-options \"-Xmx~{command_mem}m\" GetSampleName -R ~{ref_fasta} -I ~{normal_bam} -O normal_name.txt -encode\n            normal_command_line=\"-I ~{normal_bam} -normal `cat normal_name.txt`\"\n        fi\n\n        gatk --java-options \"-Xmx~{command_mem}m\" Mutect2 \\\n            -R ~{ref_fasta} \\\n            $tumor_command_line \\\n            $normal_command_line \\\n            ~{\"--germline-resource \" + gnomad} \\\n            ~{\"-pon \" + pon} \\\n            ~{\"-L \" + intervals} \\\n            ~{\"--alleles \" + gga_vcf} \\\n            -O \"~{output_vcf}\" \\\n            ~{true='--bam-output bamout.bam' false='' make_bamout} \\\n            ~{true='--f1r2-tar-gz f1r2.tar.gz' false='' run_ob_filter} \\\n            ~{m2_extra_args}\n\n        m2_exit_code=$?\n\n        ### GetPileupSummaries\n\n        # If the variants for contamination and the intervals for this scatter don't intersect, GetPileupSummaries\n        # throws an error.  However, there is nothing wrong with an empty intersection for our purposes; it simply doesn't\n        # contribute to the merged pileup summaries that we create downstream.  We implement this by with array outputs.\n        # If the tool errors, no table is created and the glob yields an empty array.\n        set +e\n\n        if [[ ! -z \"~{variants_for_contamination}\" ]]; then\n            gatk --java-options \"-Xmx~{command_mem}m\" GetPileupSummaries -R ~{ref_fasta} -I ~{tumor_bam} ~{\"--interval-set-rule INTERSECTION -L \" + intervals} \\\n                -V ~{variants_for_contamination} -L ~{variants_for_contamination} -O tumor-pileups.table\n\n            if [[ ! -z \"~{normal_bam}\" ]]; then\n                gatk --java-options \"-Xmx~{command_mem}m\" GetPileupSummaries -R ~{ref_fasta} -I ~{normal_bam} ~{\"--interval-set-rule INTERSECTION -L \" + intervals} \\\n                    -V ~{variants_for_contamination} -L ~{variants_for_contamination} -O normal-pileups.table\n            fi\n        fi\n\n        # the script only fails if Mutect2 itself fails\n        exit $m2_exit_code\n    >>>\n\n    runtime {\n        docker: gatk_docker\n        bootDiskSizeGb: 12\n        memory: machine_mem + \" MB\"\n        disks: \"local-disk \" + select_first([disk_space, 100]) + if use_ssd then \" SSD\" else \" HDD\"\n        preemptible: select_first([preemptible, 10])\n        maxRetries: select_first([max_retries, 0])\n        cpu: select_first([cpu, 1])\n    }\n\n    output {\n        File unfiltered_vcf = \"~{output_vcf}\"\n        File unfiltered_vcf_idx = \"~{output_vcf_idx}\"\n        File output_bamOut = \"bamout.bam\"\n        String tumor_sample = read_string(\"tumor_name.txt\")\n        String normal_sample = read_string(\"normal_name.txt\")\n        File stats = \"~{output_stats}\"\n        File f1r2_counts = \"f1r2.tar.gz\"\n        Array[File] tumor_pileups = glob(\"*tumor-pileups.table\")\n        Array[File] normal_pileups = glob(\"*normal-pileups.table\")\n    }\n}\n\ntask MergeVCFs {\n    input {\n      Array[File] input_vcfs\n      Array[File] input_vcf_indices\n      String output_name\n      Boolean compress\n      Runtime runtime_params\n    }\n\n    String output_vcf = output_name + if compress then \".vcf.gz\" else \".vcf\"\n    String output_vcf_idx = output_vcf + if compress then \".tbi\" else \".idx\"\n\n    # using MergeVcfs instead of GatherVcfs so we can create indices\n    # WARNING 2015-10-28 15:01:48 GatherVcfs  Index creation not currently supported when gathering block compressed VCFs.\n    command {\n        set -e\n        export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" runtime_params.gatk_override}\n        gatk --java-options \"-Xmx~{runtime_params.command_mem}m\" MergeVcfs -I ~{sep=' -I ' input_vcfs} -O ~{output_vcf}\n    }\n\n    runtime {\n        docker: runtime_params.gatk_docker\n        bootDiskSizeGb: runtime_params.boot_disk_size\n        memory: runtime_params.machine_mem + \" MB\"\n        disks: \"local-disk \" + runtime_params.disk + \" HDD\"\n        preemptible: runtime_params.preemptible\n        maxRetries: runtime_params.max_retries\n        cpu: runtime_params.cpu\n    }\n\n    output {\n        File merged_vcf = \"~{output_vcf}\"\n        File merged_vcf_idx = \"~{output_vcf_idx}\"\n    }\n}\n\ntask MergeBamOuts {\n    input {\n      File ref_fasta\n      File ref_fai\n      File ref_dict\n      Array[File]+ bam_outs\n      String output_vcf_name\n      Runtime runtime_params\n      Int? disk_space   #override to request more disk than default small task params\n    }\n\n    command <<<\n        # This command block assumes that there is at least one file in bam_outs.\n        #  Do not call this task if len(bam_outs) == 0\n        set -e\n        export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" runtime_params.gatk_override}\n        gatk --java-options \"-Xmx~{runtime_params.command_mem}m\" GatherBamFiles \\\n            -I ~{sep=\" -I \" bam_outs} -O unsorted.out.bam -R ~{ref_fasta}\n\n        # We must sort because adjacent scatters may have overlapping (padded) assembly regions, hence\n        # overlapping bamouts\n\n        gatk --java-options \"-Xmx~{runtime_params.command_mem}m\" SortSam -I unsorted.out.bam \\\n            -O ~{output_vcf_name}.out.bam \\\n            --SORT_ORDER coordinate -VALIDATION_STRINGENCY LENIENT\n        gatk --java-options \"-Xmx~{runtime_params.command_mem}m\" BuildBamIndex -I ~{output_vcf_name}.out.bam -VALIDATION_STRINGENCY LENIENT\n    >>>\n\n    runtime {\n        docker: runtime_params.gatk_docker\n        bootDiskSizeGb: runtime_params.boot_disk_size\n        memory: runtime_params.machine_mem + \" MB\"\n        disks: \"local-disk \" + select_first([disk_space, runtime_params.disk]) + \" HDD\"\n        preemptible: runtime_params.preemptible\n        maxRetries: runtime_params.max_retries\n        cpu: runtime_params.cpu\n    }\n\n    output {\n        File merged_bam_out = \"~{output_vcf_name}.out.bam\"\n        File merged_bam_out_index = \"~{output_vcf_name}.out.bai\"\n    }\n}\n\n\ntask MergeStats {\n    input {\n      Array[File]+ stats\n      Runtime runtime_params\n    }\n\n    command {\n        set -e\n        export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" runtime_params.gatk_override}\n\n\n        gatk --java-options \"-Xmx~{runtime_params.command_mem}m\" MergeMutectStats \\\n            -stats ~{sep=\" -stats \" stats} -O merged.stats\n    }\n\n    runtime {\n        docker: runtime_params.gatk_docker\n        bootDiskSizeGb: runtime_params.boot_disk_size\n        memory: runtime_params.machine_mem + \" MB\"\n        disks: \"local-disk \" + runtime_params.disk + \" HDD\"\n        preemptible: runtime_params.preemptible\n        maxRetries: runtime_params.max_retries\n        cpu: runtime_params.cpu\n    }\n\n    output {\n        File merged_stats = \"merged.stats\"\n    }\n}\n\ntask MergePileupSummaries {\n    input {\n      Array[File] input_tables\n      String output_name\n      File ref_dict\n      Runtime runtime_params\n    }\n\n    command {\n        set -e\n        export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" runtime_params.gatk_override}\n\n        gatk --java-options \"-Xmx~{runtime_params.command_mem}m\" GatherPileupSummaries \\\n        --sequence-dictionary ~{ref_dict} \\\n        -I ~{sep=' -I ' input_tables} \\\n        -O ~{output_name}.tsv\n    }\n\n    runtime {\n        docker: runtime_params.gatk_docker\n        bootDiskSizeGb: runtime_params.boot_disk_size\n        memory: runtime_params.machine_mem + \" MB\"\n        disks: \"local-disk \" + runtime_params.disk + \" HDD\"\n        preemptible: runtime_params.preemptible\n        maxRetries: runtime_params.max_retries\n        cpu: runtime_params.cpu\n    }\n\n    output {\n        File merged_table = \"~{output_name}.tsv\"\n    }\n}\n\n# Learning step of the orientation bias mixture model, which is the recommended orientation bias filter as of September 2018\ntask LearnReadOrientationModel {\n    input {\n      Array[File] f1r2_tar_gz\n      Runtime runtime_params\n      Int? mem  #override memory\n    }\n\n    Int machine_mem = select_first([mem, runtime_params.machine_mem])\n    Int command_mem = machine_mem - 1000\n\n    command {\n        set -e\n        export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" runtime_params.gatk_override}\n\n        gatk --java-options \"-Xmx~{command_mem}m\" LearnReadOrientationModel \\\n            -I ~{sep=\" -I \" f1r2_tar_gz} \\\n            -O \"artifact-priors.tar.gz\"\n    }\n\n    runtime {\n        docker: runtime_params.gatk_docker\n        bootDiskSizeGb: runtime_params.boot_disk_size\n        memory: machine_mem + \" MB\"\n        disks: \"local-disk \" + runtime_params.disk + \" HDD\"\n        preemptible: runtime_params.preemptible\n        maxRetries: runtime_params.max_retries\n        cpu: runtime_params.cpu\n    }\n\n    output {\n        File artifact_prior_table = \"artifact-priors.tar.gz\"\n    }\n\n}\n\ntask CalculateContamination {\n    input {\n      String? intervals\n      File tumor_pileups\n      File? normal_pileups\n      Runtime runtime_params\n    }\n\n    command {\n        set -e\n\n        export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" runtime_params.gatk_override}\n\n        gatk --java-options \"-Xmx~{runtime_params.command_mem}m\" CalculateContamination -I ~{tumor_pileups} \\\n        -O contamination.table --tumor-segmentation segments.table ~{\"-matched \" + normal_pileups}\n    }\n\n    runtime {\n        docker: runtime_params.gatk_docker\n        bootDiskSizeGb: runtime_params.boot_disk_size\n        memory: runtime_params.machine_mem + \" MB\"\n        disks: \"local-disk \" + runtime_params.disk + \" HDD\"\n        preemptible: runtime_params.preemptible\n        maxRetries: runtime_params.max_retries\n        cpu: runtime_params.cpu\n    }\n\n    output {\n        File contamination_table = \"contamination.table\"\n        File maf_segments = \"segments.table\"\n    }\n}\n\ntask Filter {\n    input {\n      File? intervals\n      File ref_fasta\n      File ref_fai\n      File ref_dict\n      File unfiltered_vcf\n      File unfiltered_vcf_idx\n      String output_name\n      Boolean compress\n      File? mutect_stats\n      File? artifact_priors_tar_gz\n      File? contamination_table\n      File? maf_segments\n      String? m2_extra_filtering_args\n\n      Runtime runtime_params\n      Int? disk_space\n    }\n\n    String output_vcf = output_name + if compress then \".vcf.gz\" else \".vcf\"\n    String output_vcf_idx = output_vcf + if compress then \".tbi\" else \".idx\"\n\n    parameter_meta{\n      ref_fasta: {localization_optional: true}\n      ref_fai: {localization_optional: true}\n      ref_dict: {localization_optional: true}\n    }\n\n    command {\n        set -e\n\n        export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" runtime_params.gatk_override}\n\n        gatk --java-options \"-Xmx~{runtime_params.command_mem}m\" FilterMutectCalls -V ~{unfiltered_vcf} \\\n            -R ~{ref_fasta} \\\n            -O ~{output_vcf} \\\n            ~{\"--contamination-table \" + contamination_table} \\\n            ~{\"--tumor-segmentation \" + maf_segments} \\\n            ~{\"--ob-priors \" + artifact_priors_tar_gz} \\\n            ~{\"-stats \" + mutect_stats} \\\n            --filtering-stats filtering.stats \\\n            ~{m2_extra_filtering_args}\n    }\n\n    runtime {\n        docker: runtime_params.gatk_docker\n        bootDiskSizeGb: runtime_params.boot_disk_size\n        memory: runtime_params.machine_mem + \" MB\"\n        disks: \"local-disk \" + select_first([disk_space, runtime_params.disk]) + \" HDD\"\n        preemptible: runtime_params.preemptible\n        maxRetries: runtime_params.max_retries\n        cpu: runtime_params.cpu\n    }\n\n    output {\n        File filtered_vcf = \"~{output_vcf}\"\n        File filtered_vcf_idx = \"~{output_vcf_idx}\"\n        File filtering_stats = \"filtering.stats\"\n    }\n}\n\ntask FilterAlignmentArtifacts {\n    input {\n      File ref_fasta\n      File ref_fai\n      File ref_dict\n      File input_vcf\n      File input_vcf_idx\n      File bam\n      File bai\n      String output_name\n      Boolean compress\n      File realignment_index_bundle\n      String? realignment_extra_args\n      Runtime runtime_params\n      Int mem\n    }\n\n    String output_vcf = output_name + if compress then \".vcf.gz\" else \".vcf\"\n    String output_vcf_idx = output_vcf +  if compress then \".tbi\" else \".idx\"\n\n    Int machine_mem = mem\n    Int command_mem = machine_mem - 500\n\n    parameter_meta{\n      ref_fasta: {localization_optional: true}\n      ref_fai: {localization_optional: true}\n      ref_dict: {localization_optional: true}\n      input_vcf: {localization_optional: true}\n      input_vcf_idx: {localization_optional: true}\n      bam: {localization_optional: true}\n      bai: {localization_optional: true}\n    }\n\n    command {\n        set -e\n\n        export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" runtime_params.gatk_override}\n\n        gatk --java-options \"-Xmx~{command_mem}m\" FilterAlignmentArtifacts \\\n            -R ~{ref_fasta} \\\n            -V ~{input_vcf} \\\n            -I ~{bam} \\\n            --bwa-mem-index-image ~{realignment_index_bundle} \\\n            ~{realignment_extra_args} \\\n            -O ~{output_vcf}\n    }\n\n    runtime {\n        docker: runtime_params.gatk_docker\n        bootDiskSizeGb: runtime_params.boot_disk_size\n        memory: machine_mem + \" MB\"\n        disks: \"local-disk \" + runtime_params.disk + \" HDD\"\n        preemptible: runtime_params.preemptible\n        maxRetries: runtime_params.max_retries\n        cpu: runtime_params.cpu\n    }\n\n    output {\n        File filtered_vcf = \"~{output_vcf}\"\n        File filtered_vcf_idx = \"~{output_vcf_idx}\"\n    }\n}\n\ntask Funcotate {\n     input {\n       File ref_fasta\n       File ref_fai\n       File ref_dict\n       File input_vcf\n       File input_vcf_idx\n       String reference_version\n       String output_file_base_name\n       String output_format\n       Boolean compress\n       Boolean use_gnomad\n       # This should be updated when a new version of the data sources is released\n       # TODO: Make this dynamically chosen in the command.\n       File? data_sources_tar_gz = \"gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.6.20190124s.tar.gz\"\n       String? control_id\n       String? case_id\n       String? sequencing_center\n       String? sequence_source\n       String? transcript_selection_mode\n       File? transcript_selection_list\n       Array[String]? annotation_defaults\n       Array[String]? annotation_overrides\n       Array[String]? funcotator_excluded_fields\n       Boolean? filter_funcotations\n       File? interval_list\n\n       String? extra_args\n\n       # ==============\n       Runtime runtime_params\n       Int? disk_space   #override to request more disk than default small task params\n\n       # You may have to change the following two parameter values depending on the task requirements\n       Int default_ram_mb = 3000\n       # WARNING: In the workflow, you should calculate the disk space as an input to this task (disk_space_gb).  Please see [TODO: Link from Jose] for examples.\n       Int default_disk_space_gb = 100\n     }\n\n     # ==============\n     # Process input args:\n     String output_maf = output_file_base_name + \".maf\"\n     String output_maf_index = output_maf + \".idx\"\n     String output_vcf = output_file_base_name + if compress then \".vcf.gz\" else \".vcf\"\n     String output_vcf_idx = output_vcf +  if compress then \".tbi\" else \".idx\"\n     String output_file = if output_format == \"MAF\" then output_maf else output_vcf\n     String output_file_index = if output_format == \"MAF\" then output_maf_index else output_vcf_idx\n     String transcript_selection_arg = if defined(transcript_selection_list) then \" --transcript-list \" else \"\"\n     String annotation_def_arg = if defined(annotation_defaults) then \" --annotation-default \" else \"\"\n     String annotation_over_arg = if defined(annotation_overrides) then \" --annotation-override \" else \"\"\n     String filter_funcotations_args = if defined(filter_funcotations) && (filter_funcotations) then \" --remove-filtered-variants \" else \"\"\n     String excluded_fields_args = if defined(funcotator_excluded_fields) then \" --exclude-field \" else \"\"\n     String interval_list_arg = if defined(interval_list) then \" -L \" else \"\"\n     String extra_args_arg = select_first([extra_args, \"\"])\n\n     String dollar = \"$\"\n\n     parameter_meta{\n      ref_fasta: {localization_optional: true}\n      ref_fai: {localization_optional: true}\n      ref_dict: {localization_optional: true}\n      input_vcf: {localization_optional: true}\n      input_vcf_idx: {localization_optional: true}\n     }\n\n     command <<<\n         set -e\n         export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" runtime_params.gatk_override}\n\n         # Extract our data sources:\n         echo \"Extracting data sources zip file...\"\n         mkdir datasources_dir\n         tar zxvf ~{data_sources_tar_gz} -C datasources_dir --strip-components 1\n         DATA_SOURCES_FOLDER=\"$PWD/datasources_dir\"\n\n         # Handle gnomAD:\n         if ~{use_gnomad} ; then\n             echo \"Enabling gnomAD...\"\n             for potential_gnomad_gz in gnomAD_exome.tar.gz gnomAD_genome.tar.gz ; do\n                 if [[ -f ~{dollar}{DATA_SOURCES_FOLDER}/~{dollar}{potential_gnomad_gz} ]] ; then\n                     cd ~{dollar}{DATA_SOURCES_FOLDER}\n                     tar -zvxf ~{dollar}{potential_gnomad_gz}\n                     cd -\n                 else\n                     echo \"ERROR: Cannot find gnomAD folder: ~{dollar}{potential_gnomad_gz}\" 1>&2\n                     false\n                 fi\n             done\n         fi\n\n         # Run Funcotator:\n         gatk --java-options \"-Xmx~{runtime_params.command_mem}m\" Funcotator \\\n             --data-sources-path $DATA_SOURCES_FOLDER \\\n             --ref-version ~{reference_version} \\\n             --output-file-format ~{output_format} \\\n             -R ~{ref_fasta} \\\n             -V ~{input_vcf} \\\n             -O ~{output_file} \\\n             ~{interval_list_arg} ~{default=\"\" interval_list} \\\n             --annotation-default normal_barcode:~{default=\"Unknown\" control_id} \\\n             --annotation-default tumor_barcode:~{default=\"Unknown\" case_id} \\\n             --annotation-default Center:~{default=\"Unknown\" sequencing_center} \\\n             --annotation-default source:~{default=\"Unknown\" sequence_source} \\\n             ~{\"--transcript-selection-mode \" + transcript_selection_mode} \\\n             ~{transcript_selection_arg}~{default=\"\" sep=\" --transcript-list \" transcript_selection_list} \\\n             ~{annotation_def_arg}~{default=\"\" sep=\" --annotation-default \" annotation_defaults} \\\n             ~{annotation_over_arg}~{default=\"\" sep=\" --annotation-override \" annotation_overrides} \\\n             ~{excluded_fields_args}~{default=\"\" sep=\" --exclude-field \" funcotator_excluded_fields} \\\n             ~{filter_funcotations_args} \\\n             ~{extra_args_arg}\n         # Make sure we have a placeholder index for MAF files so this workflow doesn't fail:\n         if [[ \"~{output_format}\" == \"MAF\" ]] ; then\n            touch ~{output_maf_index}\n         fi\n     >>>\n\n    runtime {\n        docker: runtime_params.gatk_docker\n        bootDiskSizeGb: runtime_params.boot_disk_size\n        memory: runtime_params.machine_mem + \" MB\"\n        disks: \"local-disk \" + select_first([disk_space, runtime_params.disk]) + \" HDD\"\n        preemptible: runtime_params.preemptible\n        maxRetries: runtime_params.max_retries\n        cpu: runtime_params.cpu\n    }\n\n     output {\n         File funcotated_output_file = \"~{output_file}\"\n         File funcotated_output_file_index = \"~{output_file_index}\"\n     }\n}\n","checksum":[{"checksum":"713497c26dcf5ca065c98334a37309e33c9d16c1f6f3d99b629a594c5c14d759","type":"sha256"}],"url":"https://zenodo.org/api/files/b46e9f32-49d8-4d1c-8adf-f116e3bd2da2/mutect2.wdl"}